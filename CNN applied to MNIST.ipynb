{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/Adam/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/Adam/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/Adam/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/Adam/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "## Import Data\n",
    "\n",
    "\"\"\"A deep MNIST classifier using convolutional layers.\n",
    "\n",
    "See extensive documentation at\n",
    "https://www.tensorflow.org/get_started/mnist/pros\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/Users/Adam/MNIST_data/\",one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define Various models for experimentation\n",
    "\n",
    "##1. Simple Fully Connected NN with relu acitvation\n",
    "def SimpleNN(x, training_phase):\n",
    "    h1 = FullyConnected(x, 100, 'h1')\n",
    "#    h1_norm = tf.layers.batch_normalization(h1, training=trainingPhase,  name='bn1')\n",
    "    h1_relu = tf.nn.sigmoid(h1)\n",
    "    y = FullyConnected(h1_relu, 10, 'y')\n",
    "    return y \n",
    "\n",
    "##2. Fully Connected NN wirth relu activation and batch normalisation to avoid covariance shift\n",
    "# This is the first model that actually uses the training_phase parameter\n",
    "def SimpleNN(input, training_phase):\n",
    "    h1 = FullyConnected(input, 100, 'h1')\n",
    "  \n",
    "    h1_norm = tf.layers.batch_normalization(h1, training=trainingPhase,  name='bn1')\n",
    "    h1_relu = tf.nn.relu(h1_norm)\n",
    "    \n",
    "    h2 = FullyConnected(h1_relu, 100, 'h2')\n",
    "    h2_norm = tf.layers.batch_normalization(h2, training=trainingPhase, name='bn2')\n",
    "    h2_relu = tf.nn.relu(h2_norm)\n",
    "    \n",
    "    h3 = FullyConnected(h2_relu, 100, 'h3')\n",
    "        \n",
    "    h4 = FullyConnected(h3, 10, 'h4')\n",
    "    return h4\n",
    "\n",
    "##3. Convolutional Neural Network -  5x5 kernel with dropout\n",
    "def Convolutional_simpleNN(input, trainin_phase, keep_prob):\n",
    "    rs = tf.reshape(input, [-1, 28, 28, 1])\n",
    "\n",
    "    # 5x5 kernel\n",
    "    # operates on one input channel\n",
    "    # outputs depth of 16 channels (16 kernels)\n",
    "    # Image will be padded if necessary for kernel\n",
    "    h1_conv = Convolutional(rs, [5, 5, 1, 32], 'h1_conv', padding='SAME') # 28 x 28 -> 28 x 28\n",
    "    h1_relu = tf.nn.relu(h1_conv)\n",
    "    h1_pool = max_pool(h1_relu, 'h1_pool', kernel_size=2, strides=2) # 28 x 28 -> 14 x 14\n",
    "    \n",
    "    #2nd conv layer\n",
    "    h2_conv = Convolutional(h1_pool, [5, 5, 32, 64], 'h2_conv', padding='SAME') # 14 x 14 -> 14 x 14\n",
    "    h2_relu = tf.nn.relu(h2_conv)\n",
    "    h2_pool = max_pool(h2_relu, 'h2_pool', kernel_size=2, strides=2) # 14 x 14 -> 7 x 7    \n",
    "    #reshape before hitting with FC layer\n",
    "    h_pool2_flat = tf.reshape(h2_pool, [-1, 7*7*64])    \n",
    "    \n",
    "    #1st FullyConnected Layer\n",
    "    FC1 = FullyConnected(h_pool2_flat, 1024, 'FC1')\n",
    "    # Dropout - controls the complexity of the model, prevents co-adaptation of\n",
    "    # features.\n",
    "    FC1_drop = tf.nn.dropout(FC1, keep_prob)\n",
    "    \n",
    "    # Map the 1024 features to 10 classes, one for each digit\n",
    "    FC2 = FullyConnected(FC1_drop,10, 'FC2')\n",
    "    \n",
    "    return FC2\n",
    "\n",
    "\n",
    "## Useful Wrapper functions\n",
    "def FullyConnected(x, output_size, name, initializer=tf.contrib.layers.variance_scaling_initializer(uniform=True)):\n",
    "    ''' \n",
    "    Wrapper for Fully Connected layer - takes care of variable scoping\n",
    "    '''\n",
    "    input_size = int(x.get_shape()[1])\n",
    "    \n",
    "    #variable scoping\n",
    "    with tf.variable_scope(name):\n",
    "        weights = tf.get_variable('weights', [input_size, output_size], initializer=initializer)\n",
    "        biases = tf.get_variable(\"biases\", [output_size], initializer=tf.constant_initializer(0.01))\n",
    "        \n",
    "        # Add the parameters to Tensorboard so we can visualise them later\n",
    "        tf.summary.histogram('weights', weights)\n",
    "        tf.summary.histogram('biases', biases)\n",
    "        \n",
    "        return tf.add(tf.matmul(x, weights), biases)\n",
    "\n",
    "\n",
    "## Wrapper for 2D convolutional layer\n",
    "def Convolutional(x, kernel_shape, name, \n",
    "                 padding='SAME', \n",
    "                 strides=1, \n",
    "                 initializer=tf.contrib.layers.variance_scaling_initializer(uniform=True)):\n",
    "    '''\n",
    "    Wrapper for a 2d convolutional layer\n",
    "    params: x - The input data, should be a 4D tensor\n",
    "            kernel_shape - The shape of the convolution kernel. Shape should be as follows:\n",
    "                            [kernel_width, kernel_height, input_depth, num_kernels]\n",
    "                            input_depth is number of input channels (i.e 1 for black and white)\n",
    "                            num_kernels is the number of output channels.\n",
    "            name - to take care of variable scopring in tf\n",
    "            padding - padding scheme: Must be the string 'SAME' or 'VALID'. Valid padding will pad the input matrix with zeros \n",
    "            the minimum required to ensure dimensions are consitent with convolution of kernels. Same padding will pad the input \n",
    "            matrix such that the output of convolution with the kernel has the same dimensions as the input\n",
    "            strides - How much the kernel should slide in each step. We assume width=height\n",
    "            initializer - initialisation scheme for our weights\n",
    "    '''\n",
    "    bias_shape = kernel_shape[3]\n",
    "    with tf.variable_scope(name):\n",
    "        weights = tf.get_variable('weights', kernel_shape, initializer=initializer)\n",
    "        biases = tf.get_variable(\"biases\", bias_shape,initializer=tf.constant_initializer(0.01))\n",
    "        \n",
    "        # Add the parameters to Tensorboard so we can visualise them later\n",
    "        tf.summary.histogram('weights', weights)\n",
    "        tf.summary.histogram('biases', biases)\n",
    "        \n",
    "        x = tf.nn.conv2d(x, weights, strides=[1, strides, strides, 1], padding=padding)\n",
    "        return x + biases\n",
    "\n",
    "## Wrapper for max pooling\n",
    "def max_pool(x, name, padding='VALID', strides=2, kernel_size=2):\n",
    "    '''\n",
    "    Wrapper for a maxpool convolutional layer. Performs pooling as to reduce dimensions of output of conv. layer\n",
    "    Only using square kernels\n",
    "    '''\n",
    "    with tf.variable_scope(name):\n",
    "        return tf.nn.max_pool(x, ksize=[1, kernel_size, kernel_size, 1], strides=[1, strides, strides, 1], padding=padding)\n",
    "\n",
    "## Utility function for finding number of params of NN\n",
    "def count_params():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        shape = variable.get_shape()\n",
    "        variable_parametes = 1\n",
    "        for dim in shape:\n",
    "            variable_parametes *= dim.value\n",
    "        total_parameters += variable_parametes\n",
    "    print(\"There are \" +str(total_parameters) + \" parameters.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3374744 parameters.\n",
      " step      0: - test accuracy simple =   0.148, test accuracy conv =  0.211\n",
      " step    100: - test accuracy simple =   0.695, test accuracy conv =  0.977\n",
      " step    200: - test accuracy simple =   0.859, test accuracy conv =  0.977\n",
      " step    300: - test accuracy simple =   0.859, test accuracy conv =  0.977\n",
      " step    400: - test accuracy simple =   0.883, test accuracy conv =  0.984\n",
      " step    500: - test accuracy simple =   0.922, test accuracy conv =  0.953\n",
      " step    600: - test accuracy simple =   0.930, test accuracy conv =  0.984\n",
      " step    700: - test accuracy simple =   0.891, test accuracy conv =  0.969\n",
      " step    800: - test accuracy simple =   0.789, test accuracy conv =  0.977\n",
      " step    900: - test accuracy simple =   0.812, test accuracy conv =  0.969\n",
      " step   1000: - test accuracy simple =   0.859, test accuracy conv =  0.977\n",
      " step   1100: - test accuracy simple =   0.844, test accuracy conv =  0.977\n",
      " step   1200: - test accuracy simple =   0.773, test accuracy conv =  1.000\n",
      " step   1300: - test accuracy simple =   0.789, test accuracy conv =  0.977\n",
      " step   1400: - test accuracy simple =   0.836, test accuracy conv =  0.984\n",
      " step   1500: - test accuracy simple =   0.836, test accuracy conv =  0.984\n",
      " step   1600: - test accuracy simple =   0.742, test accuracy conv =  0.969\n",
      " step   1700: - test accuracy simple =   0.789, test accuracy conv =  0.984\n",
      " step   1800: - test accuracy simple =   0.805, test accuracy conv =  0.992\n",
      " step   1900: - test accuracy simple =   0.859, test accuracy conv =  0.969\n",
      " step   2000: - test accuracy simple =   0.805, test accuracy conv =  0.984\n",
      " step   2100: - test accuracy simple =   0.859, test accuracy conv =  1.000\n",
      " step   2200: - test accuracy simple =   0.750, test accuracy conv =  0.977\n",
      " step   2300: - test accuracy simple =   0.820, test accuracy conv =  0.992\n",
      " step   2400: - test accuracy simple =   0.820, test accuracy conv =  0.984\n",
      " step   2500: - test accuracy simple =   0.836, test accuracy conv =  0.992\n",
      " step   2600: - test accuracy simple =   0.836, test accuracy conv =  0.977\n",
      " step   2700: - test accuracy simple =   0.805, test accuracy conv =  0.984\n",
      " step   2800: - test accuracy simple =   0.859, test accuracy conv =  0.977\n",
      " step   2900: - test accuracy simple =   0.758, test accuracy conv =  0.969\n",
      " step   3000: - test accuracy simple =   0.789, test accuracy conv =  0.984\n",
      " step   3100: - test accuracy simple =   0.828, test accuracy conv =  0.992\n",
      " step   3200: - test accuracy simple =   0.742, test accuracy conv =  0.984\n",
      " step   3300: - test accuracy simple =   0.844, test accuracy conv =  0.984\n",
      " step   3400: - test accuracy simple =   0.766, test accuracy conv =  1.000\n",
      " step   3500: - test accuracy simple =   0.781, test accuracy conv =  0.984\n",
      " step   3600: - test accuracy simple =   0.859, test accuracy conv =  1.000\n",
      " step   3700: - test accuracy simple =   0.734, test accuracy conv =  0.961\n",
      " step   3800: - test accuracy simple =   0.820, test accuracy conv =  0.992\n",
      " step   3900: - test accuracy simple =   0.828, test accuracy conv =  1.000\n",
      " step   4000: - test accuracy simple =   0.859, test accuracy conv =  0.992\n",
      " step   4100: - test accuracy simple =   0.906, test accuracy conv =  0.992\n",
      " step   4200: - test accuracy simple =   0.844, test accuracy conv =  1.000\n",
      " step   4300: - test accuracy simple =   0.875, test accuracy conv =  0.992\n",
      " step   4400: - test accuracy simple =   0.828, test accuracy conv =  0.977\n",
      " step   4500: - test accuracy simple =   0.875, test accuracy conv =  0.992\n",
      " step   4600: - test accuracy simple =   0.828, test accuracy conv =  0.992\n",
      " step   4700: - test accuracy simple =   0.867, test accuracy conv =  0.992\n",
      " step   4800: - test accuracy simple =   0.930, test accuracy conv =  1.000\n",
      " step   4900: - test accuracy simple =   0.898, test accuracy conv =  1.000\n",
      " step   5000: - test accuracy simple =   0.867, test accuracy conv =  1.000\n",
      " step   5100: - test accuracy simple =   0.836, test accuracy conv =  0.977\n",
      " step   5200: - test accuracy simple =   0.914, test accuracy conv =  0.992\n",
      " step   5300: - test accuracy simple =   0.812, test accuracy conv =  1.000\n",
      " step   5400: - test accuracy simple =   0.875, test accuracy conv =  1.000\n",
      " step   5500: - test accuracy simple =   0.859, test accuracy conv =  1.000\n",
      " step   5600: - test accuracy simple =   0.859, test accuracy conv =  1.000\n",
      " step   5700: - test accuracy simple =   0.898, test accuracy conv =  1.000\n",
      " step   5800: - test accuracy simple =   0.867, test accuracy conv =  1.000\n",
      " step   5900: - test accuracy simple =   0.867, test accuracy conv =  1.000\n",
      " step   6000: - test accuracy simple =   0.828, test accuracy conv =  1.000\n",
      " step   6100: - test accuracy simple =   0.773, test accuracy conv =  0.992\n",
      " step   6200: - test accuracy simple =   0.852, test accuracy conv =  0.984\n",
      " step   6300: - test accuracy simple =   0.812, test accuracy conv =  1.000\n",
      " step   6400: - test accuracy simple =   0.852, test accuracy conv =  1.000\n",
      " step   6500: - test accuracy simple =   0.930, test accuracy conv =  0.984\n",
      " step   6600: - test accuracy simple =   0.852, test accuracy conv =  1.000\n",
      " step   6700: - test accuracy simple =   0.914, test accuracy conv =  1.000\n",
      " step   6800: - test accuracy simple =   0.891, test accuracy conv =  1.000\n",
      " step   6900: - test accuracy simple =   0.914, test accuracy conv =  1.000\n",
      " step   7000: - test accuracy simple =   0.898, test accuracy conv =  0.992\n",
      " step   7100: - test accuracy simple =   0.883, test accuracy conv =  1.000\n",
      " step   7200: - test accuracy simple =   0.914, test accuracy conv =  1.000\n",
      " step   7300: - test accuracy simple =   0.891, test accuracy conv =  1.000\n",
      " step   7400: - test accuracy simple =   0.883, test accuracy conv =  0.992\n",
      " step   7500: - test accuracy simple =   0.750, test accuracy conv =  0.969\n",
      " step   7600: - test accuracy simple =   0.742, test accuracy conv =  0.961\n",
      " step   7700: - test accuracy simple =   0.789, test accuracy conv =  0.992\n",
      " step   7800: - test accuracy simple =   0.836, test accuracy conv =  0.984\n",
      " step   7900: - test accuracy simple =   0.805, test accuracy conv =  0.992\n",
      " step   8000: - test accuracy simple =   0.906, test accuracy conv =  0.984\n",
      " step   8100: - test accuracy simple =   0.836, test accuracy conv =  0.977\n",
      " step   8200: - test accuracy simple =   0.875, test accuracy conv =  1.000\n",
      " step   8300: - test accuracy simple =   0.883, test accuracy conv =  0.984\n",
      " step   8400: - test accuracy simple =   0.820, test accuracy conv =  0.992\n",
      " step   8500: - test accuracy simple =   0.781, test accuracy conv =  0.969\n",
      " step   8600: - test accuracy simple =   0.875, test accuracy conv =  0.992\n",
      " step   8700: - test accuracy simple =   0.805, test accuracy conv =  0.977\n",
      " step   8800: - test accuracy simple =   0.891, test accuracy conv =  0.984\n",
      " step   8900: - test accuracy simple =   0.844, test accuracy conv =  1.000\n",
      " step   9000: - test accuracy simple =   0.852, test accuracy conv =  1.000\n",
      " step   9100: - test accuracy simple =   0.805, test accuracy conv =  0.984\n",
      " step   9200: - test accuracy simple =   0.805, test accuracy conv =  0.984\n",
      " step   9300: - test accuracy simple =   0.859, test accuracy conv =  0.992\n",
      " step   9400: - test accuracy simple =   0.867, test accuracy conv =  0.992\n",
      " step   9500: - test accuracy simple =   0.859, test accuracy conv =  0.984\n",
      " step   9600: - test accuracy simple =   0.812, test accuracy conv =  0.992\n",
      " step   9700: - test accuracy simple =   0.805, test accuracy conv =  0.992\n",
      " step   9800: - test accuracy simple =   0.852, test accuracy conv =  0.992\n",
      " step   9900: - test accuracy simple =   0.797, test accuracy conv =  0.992\n",
      "SIMPLE NN Test Accuracy:  0.853  -  CONV NN Test Accuracy:  0.990\n"
     ]
    }
   ],
   "source": [
    "##define data inputs\n",
    "tf.reset_default_graph()\n",
    "## size of input images: 28 * 28 = 784 \n",
    "x_input = tf.placeholder(tf.float32, [None, 784])\n",
    "## size of number of classes 0, 1, ..., 9\n",
    "y_input = tf.placeholder(tf.float32, [None, 10])\n",
    "##trainingPhase - used in caluclation of Batch statistics for batch normalisation\n",
    "trainingPhase = tf.placeholder(tf.bool, name='phase')\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "#simpleNN\n",
    "prediction = SimpleNN(x_input, trainingPhase)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y_input))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y_input, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(10e-4).minimize(cost)\n",
    "\n",
    "#convNN\n",
    "prediction_conv = Convolutional_simpleNN(x_input, trainingPhase, keep_prob)\n",
    "cost_conv = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction_conv, labels=y_input))\n",
    "\n",
    "correct_prediction_conv = tf.equal(tf.argmax(prediction_conv, 1), tf.argmax(y_input, 1))\n",
    "accuracy_conv = tf.reduce_mean(tf.cast(correct_prediction_conv, tf.float32))\n",
    "\n",
    "train_step_conv = tf.train.AdamOptimizer(10e-4).minimize(cost_conv)\n",
    "\n",
    "\n",
    "#summary scalars\n",
    "training_loss = tf.summary.scalar(\"test_loss\", cost)\n",
    "training_accuracy = tf.summary.scalar(\"test_accuracy\", accuracy)\n",
    "\n",
    "training_loss_conv = tf.summary.scalar(\"test_loss\", cost_conv)\n",
    "training_accuracy_conv = tf.summary.scalar(\"test_accuracy\", accuracy_conv)\n",
    "\n",
    "count_params()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(\"/Users/Adam/Documents/Python/mnist/SimpleNN\", tf.get_default_graph())\n",
    "    writer_conv = tf.summary.FileWriter(\"/Users/Adam/Documents/Python/mnist/ConvNN\", tf.get_default_graph())\n",
    "    \n",
    "      # Train\n",
    "    for i in range(10000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(128)\n",
    "        sess.run(train_step, feed_dict={x_input: batch_xs, y_input: batch_ys, trainingPhase: True})\n",
    "        sess.run(train_step_conv, feed_dict={x_input: batch_xs, y_input: batch_ys, trainingPhase: True, keep_prob: 0.5})\n",
    "        if i % 100 == 0:\n",
    "            test_x, test_y = mnist.test.next_batch(128)\n",
    "            test_loss, test_accuracy, accPrint = sess.run([training_loss, training_accuracy, accuracy], feed_dict={x_input: test_x, y_input: test_y, trainingPhase: False})\n",
    "            test_loss_conv, test_accuracy_conv, accPrint_conv = sess.run([training_loss_conv, training_accuracy_conv, accuracy_conv], feed_dict={x_input: test_x, y_input: test_y, trainingPhase: False, keep_prob: 1})\n",
    "            writer.add_summary(test_loss, i) \n",
    "            writer.add_summary(test_accuracy, i) \n",
    "            writer.add_summary(test_loss_conv, i) \n",
    "            writer.add_summary(test_accuracy_conv, i) \n",
    "            print(' step %6d: - test accuracy simple =  %6.3f, test accuracy conv = %6.3f' % (i, accPrint, accPrint_conv))\n",
    "    writer.flush()\n",
    "    writer_conv.flush()\n",
    "    writer.close()\n",
    "    writer_conv.close()\n",
    "\n",
    "# Test trained model\n",
    "    test_acc = sess.run(accuracy, feed_dict={x_input: mnist.test.images,\n",
    "                                      y_input: mnist.test.labels,\n",
    "                                      trainingPhase: False})\n",
    "    test_acc_conv = sess.run(accuracy_conv, feed_dict={x_input: mnist.test.images,\n",
    "                                      y_input: mnist.test.labels,\n",
    "                                      trainingPhase: False, keep_prob:1.0})\n",
    "    print(\"SIMPLE NN Test Accuracy: %6.3f  -  CONV NN Test Accuracy: %6.3f\"  % (test_acc, test_acc_conv))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
